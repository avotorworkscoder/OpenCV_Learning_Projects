{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ae470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Display Image\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Read Image\n",
    "img = cv2.imread('dataset/img/uvc.jpg', 0)\n",
    "\n",
    "# Display Image\n",
    "cv2.namedWindow('Resizable window',cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('Resizable window', img)\n",
    "\n",
    "cv2.imshow('My Image2', img)\n",
    "\n",
    "# Wait for key press\n",
    "key = cv2.waitKey(0)\n",
    "if key == ord('q'):\n",
    "    print('Quitting...')\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# CLose window\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184086d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Vedio\n",
    "\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('datset/vedio/drone.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    # cv2.namedWindow('Resizable window',cv2.WINDOW_NORMAL)\n",
    "    # crop = frame[100:300, 200:500]\n",
    "    resized = cv2.resize(frame, (500, 300))\n",
    "    cv2.imshow('Drone TEST', resized)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e277db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGR to HSV Conversion\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('dataset/img/uvc.jpg')\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# ouput image\n",
    "cv2.imwrite('dataset/img/uvcOutput.jpg',hsv)\n",
    "\n",
    "cv2.imshow('HSV image', hsv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca41d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lighting (Brightness & Contrast)\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('dataset/img/uvc.jpg')\n",
    "\n",
    "# alpha = contrast, beta = brightness\n",
    "# new_pixel = alpha Ã— pixel + beta\n",
    "bright = cv2.convertScaleAbs(img, alpha = 1, beta = 50)\n",
    "\n",
    "cv2.imshow(\"Bright image\", bright)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e8c0cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webcam viewer\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19f57885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RealTime HSV viewer\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "    \n",
    "    cv2.imshow(\"HSV\", hsv)\n",
    "    cv2.imshow(\"Original\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0ddd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brighness Controller for Webcam\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Move these OUTSIDE the loop so they persist\n",
    "contrast = 1.0    # alpha (scale factor)\n",
    "brightness = 0    # beta (added value)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Apply changes: alpha=contrast, beta=brightness\n",
    "    adjusted = cv2.convertScaleAbs(frame, alpha=contrast, beta=brightness)\n",
    "\n",
    "    cv2.imshow(\"Bright Cam\", adjusted)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    \n",
    "    # Python uses 'elif' and '+=' instead of 'elseif' and '++'\n",
    "    elif key == ord('g'):\n",
    "        brightness += 5\n",
    "    elif key == ord('f'):\n",
    "        brightness -= 5\n",
    "    elif key == ord('h'):\n",
    "        contrast += 0.1\n",
    "    elif key == ord('j'):\n",
    "        contrast -= 0.1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481cb333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nAdvanced Topics in OpenCV Basics (The Missing Pieces)\\n\\n1. These are the parts most tutorials skip but real systems use constantly:\\n\\n2. Camera properties and control\\n\\n3. Image properties and memory layout\\n\\n4. Splitting and merging channels\\n\\n5. Drawing shapes and text\\n\\n6. Mouse callbacks (interactive vision tools)\\n\\n7. Trackbars (real-time parameter tuning)\\n\\n8. Video writing and recording\\n\\n9. FPS and timing control\\n\\n10. Working with regions of interest (ROI)\\n\\n11. Bitwise operations (basic masking logic)\\n\\n12. Handling different image formats and paths\\n\\n13. Window control and resizing\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Advanced Topics in OpenCV Basics (The Missing Pieces)\n",
    "\n",
    "1. These are the parts most tutorials skip but real systems use constantly:\n",
    "\n",
    "2. Camera properties and control\n",
    "\n",
    "3. Image properties and memory layout\n",
    "\n",
    "4. Splitting and merging channels\n",
    "\n",
    "5. Drawing shapes and text\n",
    "\n",
    "6. Mouse callbacks (interactive vision tools)\n",
    "\n",
    "7. Trackbars (real-time parameter tuning)\n",
    "\n",
    "8. Video writing and recording\n",
    "\n",
    "9. FPS and timing control\n",
    "\n",
    "10. Working with regions of interest (ROI)\n",
    "\n",
    "11. Bitwise operations (basic masking logic)\n",
    "\n",
    "12. Handling different image formats and paths\n",
    "\n",
    "13. Window control and resizing\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c3eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Camera Properties Control\n",
    "# You can set: Resolution, Brightness, Exposure, FPS\n",
    "\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set resolution\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cap.set(cv2.CAP_PROP_FPS, 10) # often frame rate is fixed, with auto setting options\n",
    "cap.set(cv2.CAP_PROP_BRIGHTNESS, 20)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Camera\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# To an engineer, the camera is a sensor, and every parameter is a trade-off between signal quality and processing latency.\n",
    "# Controlling these properties directly affects the success of downstream algorithms like Object Tracking or Optical Flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd68b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 The Hardware Registry (CAP_PROP)\n",
    "# When you call cap.set(), you are writing directly to the camera's internal registers. Every camera has a different Firmware Registry.\n",
    "# Property: Exposure, Brightness, Gain, Focus\n",
    "\n",
    "import cv2\n",
    "\n",
    "# cv2.CAP_DSHOW: Windows DirectShow (best for property control).\n",
    "# cv2.CAP_MSMF: Microsoft Media Foundation.\n",
    "# cv2.CAP_V4L2: Video4Linux (for Raspberry Pi/Linux).\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW) # Use DirectShow for faster access on Windows\n",
    "\n",
    "# 1. Disable Auto-Settings (The \"Manual\" Mode)\n",
    "# 0.25 is often the code for 'Manual' in many web cameras\n",
    "# '3' or '0.75' or \"1\" is the standard code for 'Auto' in many drivers (v4l2/DirectShow)\n",
    "cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.75) \n",
    "\n",
    "# 2. Set Exposure (Specific values depend on the driver)\n",
    "# Negative values like -5 or -7 are common for high-speed capture\n",
    "cap.set(cv2.CAP_PROP_EXPOSURE, 6)\n",
    "\n",
    "# 3. Buffer Control\n",
    "# Setting buffer to 1 ensures you always get the \"freshest\" frame, not an old one\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Advanced: Read and display actual metadata from the hardware\n",
    "    actual_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    actual_exp = cap.get(cv2.CAP_PROP_EXPOSURE)\n",
    "    \n",
    "    cv2.putText(frame, f\"Exp: {actual_exp} FPS: {actual_fps}\", (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Engineer View\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8147a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Reset manual mode back to Auto mode\n",
    "# When you manual-set exposure to a specific value (like 6), it stays locked at that hardware level until explicitly reset. To fix this, you need to re-enable Auto Exposure.\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "# '3' is the standard code for 'Auto' in many drivers (v4l2/DirectShow)\n",
    "# Some drivers might use '0.75' or '1' depending on the version\n",
    "cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 1) \n",
    "\n",
    "# If the above doesn't work, try forcing a reset via the Settings Dialog (Windows only)\n",
    "cap.set(cv2.CAP_PROP_SETTINGS, 1) # This pops up a manual control window\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd91f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 The \"Backdoor\" Codec Control (FourCC)\n",
    "\n",
    "# Standard USB 2.0 bandwidth cannot handle raw 1080p at 60fps. Engineers use FourCC (Four Character Code) to force the camera to compress data into MJPG or H264 inside the camera hardware before it reaches the CPU.\n",
    "# The Modern \"Golden Standard\": H.264 (AVC) H.264 (Advanced Video Coding) is the industry standard for 90% of video streaming. Unlike MJPG, which compresses every frame independently, H.264 only records changes between frames, allowing for HD quality at much lower bitrates.\n",
    "# H.265 (High Efficiency Video Coding) is the modern successor to H.264, offering up to 50% better compression for the same video quality. It is essential for 8K resolutions and high-fidelity 10-bit color.\n",
    "# For ultra-low latency where you have high bandwidth (e.g., USB 3.0), raw formats like NV12 or YUY2 are used. These provide maximum color accuracy because they avoid compression artifacts entirely.\n",
    "\n",
    "# Force hardware compression for high-speed streaming\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0910ec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(612, 612, 3)\n",
      "1123632\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# 2.Understanding Image Properties\n",
    "# An image in OpenCV is just a NumPy array.\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\")\n",
    "\n",
    "print(img.shape)\n",
    "print(img.size)\n",
    "print(img.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228abd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 img.shape (The Geometry)\n",
    "# In advanced usage, you use (.shape) to calculate Scaling Factors and Padding (vital for YOLO/CNN models).\n",
    "# Logic: height, width, channels = img.shape\n",
    "# The \"Batch\" Dimension: Deep Learning models (TensorFlow/PyTorch) expect 4 dimensions: (Batch_Size, Height, Width, Channels). \n",
    "# You use shape to transform your image for AI:\n",
    "\n",
    "# Expand 3D image (H, W, C) to 4D Batch (1, H, W, C)\n",
    "input_tensor = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "\n",
    "# Aspect Ratio Preservation: You use shape to ensure that when you resize an image, you don't stretch or squash it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54283953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 img.size (Total Pixel Count)\n",
    "# In advanced workflows, size is used for Performance Profiling and Validation.\n",
    "# Memory Estimation: size * bytes_per_pixel tells you how much RAM the image consumes.\n",
    "# Corruption Check: If img.size is 0, the image failed to load or the file is corrupted. Advanced pipelines use this to skip bad data:\n",
    "\n",
    "if img is not None and img.size > 0:\n",
    "    # process(img)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27817a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 img.dtype (Bit Depth & Precision)\n",
    "# This is arguably the most \"Advanced\" property. Most images load as uint8 (0-255), but high-end CV tasks require different types.\n",
    "# High Dynamic Range (HDR): Scientific or medical images (like X-rays) often use uint16 or float32 to capture thousands of shades of gray rather than just 256.\n",
    "# Normalized Processing: For Mathematical operations (like adding two images), uint8 will \"overflow\" (e.g., \\(200+100=44\\) in uint8 logic). You must convert the dtype to float first:\n",
    "\n",
    "# Convert to float for precise math\n",
    "img_float = img.astype('float32') / 255.0\n",
    "\n",
    "# After processing, convert back to uint8 for display\n",
    "result = (img_float * 255).astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b263906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a uint8 canvas of size 612x612\n"
     ]
    }
   ],
   "source": [
    "# Example: Advanced \"Safety First\" Loading\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\")\n",
    "\n",
    "if img is not None:\n",
    "    h, w = img.shape[:2]\n",
    "    # Advanced: Create a blank canvas of the SAME dtype and shape\n",
    "    canvas = np.zeros(img.shape, dtype=img.dtype)\n",
    "    print(f\"Created a {img.dtype} canvas of size {w}x{h}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Splitting and Merging Channels\n",
    "# Each color channel is separate data.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\")\n",
    "\n",
    "# Core funtionality\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "cv2.imshow(\"Blue\", b)\n",
    "cv2.imshow(\"Green\", g)\n",
    "cv2.imshow(\"Red\", r)\n",
    "\n",
    "# Swap to rgb\n",
    "merged = cv2.merge([r, g, b])\n",
    "cv2.imshow(\"Merged image\", merged)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# USES:\n",
    "# Noise Reduction: Blue channels are often the \"noisiest.\" You can blur only the blue channel and merge it back to clean the image without losing red/green sharpness.\n",
    "# Object Detection: If you are tracking a red ball, you subtract the Green and Blue channels from the Red channel to highlight the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4778342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Numpy Slicing:\n",
    "# NumPy Slicing is much faster because it creates a \"view\" of the data rather than copying it.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\")\n",
    "\n",
    "## Faster NumPy method\n",
    "blue_channel = img[:, :, 0]\n",
    "green_channel = img[:, :, 1]\n",
    "red_channel = img[:, :, 2]\n",
    "\n",
    "# Example: Zeroing out the Red channel entirely\n",
    "img[:, :, 2] = 0 \n",
    "\n",
    "cv2.imshow(\"New image\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# USES:\n",
    "# Noise Reduction: Blue channels are often the \"noisiest.\" You can blur only the blue channel and merge it back to clean the image without losing red/green sharpness.\n",
    "# Object Detection: If you are tracking a red ball, you subtract the Green and Blue channels from the Red channel to highlight the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc196c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Visualise channel in \"TRUE COLOR\"\n",
    "# Normally, if you cv2.imshow(\"Blue\", b), it looks grayscale. To see it in \"Blue,\" you must create a \"dummy\" array of zeros for the other channels and then merge them\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\")\n",
    "\n",
    "# Create an array of zeros with the same shape as a single channel\n",
    "zeros = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "\n",
    "# Merge with zeros to visualize the Blue channel only\n",
    "only_blue = cv2.merge([b, zeros, zeros])\n",
    "only_green = cv2.merge([zeros, g, zeros])\n",
    "only_red = cv2.merge([zeros, zeros, r])\n",
    "\n",
    "cv2.imshow(\"Blue Channel Visual\", only_blue)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# USES:\n",
    "# Noise Reduction: Blue channels are often the \"noisiest.\" You can blur only the blue channel and merge it back to clean the image without losing red/green sharpness.\n",
    "# Object Detection: If you are tracking a red ball, you subtract the Green and Blue channels from the Red channel to highlight the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Drawing Shapes and Text\n",
    "# This is essential for: Visual debugging, Overlaying data, Robotics UI\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread('dataset/img/uvc.jpg')\n",
    "height, width = img.shape[:2]\n",
    "\n",
    "cv2.line(img, (width // 2, 0), (width // 2, height), (0, 255, 0), 2) # Vertical line\n",
    "cv2.line(img, (0, height // 2), (width, height // 2), (0, 255, 0), 2) # Horizontal line\n",
    "\n",
    "# Draw a thick yellow border around the image edges\n",
    "cv2.rectangle(img, (0, 0), (width, height), (0, 255, 255), 10) \n",
    "\n",
    "cv2.circle(img, (width // 2, height // 2), 20, (0, 0, 255), -1) # Solid red center\n",
    "\n",
    "status_message = \"Status: Detecting Objects\"\n",
    "cv2.putText(img, status_message, (10, 50), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 100, 0), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Visual Debugging UI\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d7d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouse clicked at: 406 215\n",
      "Mouse clicked at: 406 215\n",
      "Mouse clicked at: 391 351\n",
      "Mouse clicked at: 474 331\n"
     ]
    }
   ],
   "source": [
    "# 5. Mouse Events\n",
    "# flags: Detects \"Chorded\" actions (e.g., \"Is the SHIFT key held while clicking?\" or \"Is the Right Mouse Button dragged?\").\n",
    "# param: This is a pointer to external data. You use it to pass variables (like a list to store coordinates) into the function without using global variables.\n",
    "\n",
    "import cv2\n",
    "\n",
    "def mouse_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Mouse clicked at:\", x, y)\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\")\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.setMouseCallback(\"Image\", mouse_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f462ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region Selected: Top-Left(91,78) to Bottom-Right(394,343)\n",
      "Region Selected: Top-Left(414,275) to Bottom-Right(514,293)\n"
     ]
    }
   ],
   "source": [
    "# 5.1 \"Drag and Drop\" (The ROI Tool)\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Global state\n",
    "drawing = False \n",
    "ix, iy = -1, -1\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\")\n",
    "\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global ix, iy, drawing, img\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            # Create a temporary copy so we don't 'smear' the rectangle\n",
    "            img_copy = img.copy()\n",
    "            cv2.rectangle(img_copy, (ix, iy), (x, y), (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Image\", img_copy)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        cv2.rectangle(img, (ix, iy), (x, y), (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        print(f\"Region Selected: Top-Left({ix},{iy}) to Bottom-Right({x},{y})\")\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.setMouseCallback(\"Image\", draw_rectangle)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) == 27: # Press 'Esc' to exit\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# The Flow:\n",
    "# 1.while loop starts.\n",
    "# 2.cv2.waitKey(1) runs > It checks the queue > \"Oh, the user clicked!\" > It jumps to mouse_event.\n",
    "# 3.mouse_event finishes (e.g., prints coordinates)\n",
    "# 4.Execution jumps back to the while loop.\n",
    "# 5.Loop repeats\n",
    "\n",
    "\n",
    "# When you stop moving the mouse, the MOUSEMOVE event stops firing. However, the while loop keeps running.\n",
    "# It immediately overwrites your \"live\" rectangle by showing the original img (which doesn't have the rectangle yet because you haven't released the button).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0c6c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 The \"Double Buffer\" Pattern\n",
    "# To fix this, the while loop should be the only place where cv2.imshow is called. The mouse callback should only update coordinates, and the loop should handle the drawing logic.\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Global state\n",
    "drawing = False \n",
    "ix, iy = -1, -1 # Starting point\n",
    "cx, cy = -1, -1 # Current point (live tracking)\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\")\n",
    "\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global ix, iy, cx, cy, drawing, img\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "        cx, cy = x, y # Initialize current position\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            cx, cy = x, y # Just update the current mouse position\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        # Finalize the rectangle onto the permanent image\n",
    "        cv2.rectangle(img, (ix, iy), (x, y), (0, 255, 0), 2)\n",
    "\n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.setMouseCallback(\"Image\", draw_rectangle)\n",
    "\n",
    "while True:\n",
    "    # 1. Always start with a fresh copy of the image for the \"Live\" view\n",
    "    temp_view = img.copy()\n",
    "\n",
    "    # 2. If we are currently dragging, draw the \"Live\" rectangle on the temp view\n",
    "    if drawing:\n",
    "        cv2.rectangle(temp_view, (ix, iy), (cx, cy), (0, 255, 0), 2)\n",
    "\n",
    "    # 3. ONLY ONE imshow call - shows either the permanent img or the live temp_view\n",
    "    cv2.imshow(\"Image\", temp_view)\n",
    "\n",
    "    if cv2.waitKey(1) == 27: # Press 'Esc' to exit\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91659631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGR Value at (526,169): [255, 255, 255]\n",
      "HSV Value: [  0   0 255]\n",
      "BGR Value at (330,265): [239, 212, 125]\n",
      "HSV Value: [ 97 122 239]\n",
      "BGR Value at (343,483): [199, 210, 218]\n",
      "HSV Value: [ 17  22 218]\n"
     ]
    }
   ],
   "source": [
    "# 5.3 The \"Color Picker\" Logic\n",
    "# You can use mouse events to sample pixels for Color Segmentation (e.g., finding the exact HSV value of a green leaf to track it).\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\")\n",
    "\n",
    "def color_picker(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Remember: OpenCV is BGR\n",
    "        blue = img[y, x, 0]\n",
    "        green = img[y, x, 1]\n",
    "        red = img[y, x, 2]\n",
    "        print(f\"BGR Value at ({x},{y}): [{blue}, {green}, {red}]\")\n",
    "        \n",
    "        # Advanced: Convert to HSV for robust tracking\n",
    "        hsv_pixel = cv2.cvtColor(np.uint8([[[blue, green, red]]]), cv2.COLOR_BGR2HSV)\n",
    "        print(f\"HSV Value: {hsv_pixel[0][0]}\")\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.setMouseCallback(\"Image\", color_picker)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) == 27: # Press 'Esc' to exit\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39a275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Left Click at (99, 67)\n",
      "Normal Left Click at (158, 132)\n",
      "Normal Left Click at (158, 132)\n",
      "Right-Click Dragging at (254, 210)\n",
      "Right-Click Dragging at (256, 209)\n",
      "Right-Click Dragging at (260, 209)\n",
      "Right-Click Dragging at (260, 209)\n",
      "Right-Click Dragging at (261, 209)\n",
      "Right-Click Dragging at (267, 211)\n",
      "Right-Click Dragging at (269, 212)\n",
      "Right-Click Dragging at (271, 213)\n",
      "Right-Click Dragging at (273, 213)\n",
      "Right-Click Dragging at (274, 214)\n",
      "Right-Click Dragging at (275, 215)\n",
      "Right-Click Dragging at (276, 216)\n",
      "Right-Click Dragging at (279, 218)\n",
      "Right-Click Dragging at (281, 220)\n",
      "Right-Click Dragging at (283, 221)\n",
      "Right-Click Dragging at (284, 221)\n",
      "Right-Click Dragging at (284, 222)\n",
      "Right-Click Dragging at (284, 223)\n",
      "Right-Click Dragging at (285, 224)\n",
      "Right-Click Dragging at (286, 225)\n",
      "Right-Click Dragging at (286, 225)\n",
      "Right-Click Dragging at (288, 226)\n",
      "Right-Click Dragging at (288, 226)\n",
      "Right-Click Dragging at (289, 227)\n",
      "Right-Click Dragging at (294, 230)\n",
      "Right-Click Dragging at (296, 232)\n",
      "Right-Click Dragging at (299, 233)\n",
      "Right-Click Dragging at (300, 233)\n",
      "Right-Click Dragging at (306, 235)\n",
      "Right-Click Dragging at (307, 235)\n",
      "Right-Click Dragging at (308, 237)\n",
      "Right-Click Dragging at (308, 237)\n",
      "Right-Click Dragging at (310, 238)\n",
      "Right-Click Dragging at (312, 238)\n",
      "Right-Click Dragging at (314, 239)\n",
      "Right-Click Dragging at (314, 240)\n",
      "Right-Click Dragging at (316, 241)\n",
      "Right-Click Dragging at (319, 243)\n",
      "Right-Click Dragging at (320, 245)\n",
      "Right-Click Dragging at (322, 245)\n",
      "Right-Click Dragging at (324, 245)\n",
      "Right-Click Dragging at (327, 246)\n",
      "Right-Click Dragging at (328, 247)\n",
      "Right-Click Dragging at (330, 248)\n",
      "Right-Click Dragging at (331, 249)\n",
      "Right-Click Dragging at (332, 250)\n",
      "Right-Click Dragging at (333, 251)\n",
      "Right-Click Dragging at (334, 251)\n",
      "Right-Click Dragging at (335, 251)\n",
      "Right-Click Dragging at (336, 251)\n",
      "Right-Click Dragging at (339, 252)\n",
      "Right-Click Dragging at (340, 252)\n",
      "Right-Click Dragging at (340, 253)\n",
      "Right-Click Dragging at (341, 253)\n",
      "Right-Click Dragging at (342, 253)\n",
      "Right-Click Dragging at (343, 253)\n",
      "Right-Click Dragging at (343, 253)\n",
      "Right-Click Dragging at (343, 254)\n",
      "Right-Click Dragging at (343, 256)\n",
      "Right-Click Dragging at (344, 256)\n",
      "Right-Click Dragging at (345, 257)\n",
      "Right-Click Dragging at (345, 258)\n",
      "Right-Click Dragging at (347, 259)\n",
      "Right-Click Dragging at (347, 260)\n",
      "Right-Click Dragging at (348, 260)\n",
      "Right-Click Dragging at (348, 260)\n",
      "Right-Click Dragging at (348, 261)\n",
      "Right-Click Dragging at (349, 262)\n",
      "Right-Click Dragging at (350, 262)\n",
      "Right-Click Dragging at (351, 262)\n",
      "Right-Click Dragging at (352, 264)\n",
      "Right-Click Dragging at (352, 265)\n",
      "Right-Click Dragging at (353, 265)\n",
      "Right-Click Dragging at (353, 265)\n",
      "Right-Click Dragging at (353, 266)\n",
      "Right-Click Dragging at (354, 266)\n",
      "Right-Click Dragging at (354, 267)\n",
      "Right-Click Dragging at (355, 267)\n",
      "Right-Click Dragging at (355, 268)\n",
      "Right-Click Dragging at (356, 268)\n"
     ]
    }
   ],
   "source": [
    "# 5.4 Mouse Event Flags (flags)\n",
    "# These indicate if a key or another mouse button was held down during the event.\n",
    "\n",
    "import cv2\n",
    "\n",
    "def advanced_mouse_event(event, x, y, flags, param):\n",
    "    # Check for a left click\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Check if SHIFT was also held down\n",
    "        if flags & cv2.EVENT_FLAG_SHIFTKEY:\n",
    "            print(f\"Shift + Left Click at {x, y} - Performing special action!\")\n",
    "        else:\n",
    "            print(f\"Normal Left Click at {x, y}\")\n",
    "\n",
    "    # Detect if user is dragging with the Right Button\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_RBUTTON:\n",
    "            print(f\"Right-Click Dragging at {x, y}\")\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\")\n",
    "cv2.namedWindow(\"Advanced Control\")\n",
    "cv2.setMouseCallback(\"Advanced Control\", advanced_mouse_event)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Advanced Control\", img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60897b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTRUCTIONS:\n",
      "1. Click two points to measure a known object.\n",
      "2. Press 'c' to enter real-world size.\n",
      "3. Press 'r' to reset points.\n",
      "4. Press 'Esc' to exit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 1 set at: (182, 59)\n",
      "Point 2 set at: (175, 349)\n",
      "Distance in Pixels: 290.08\n"
     ]
    }
   ],
   "source": [
    "# 5.5 Calibration Tools\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Global state\n",
    "points = []\n",
    "pixel_dist = 0\n",
    "scale_factor = 1.0  # Real-world units per pixel\n",
    "\n",
    "def calibrate_dist(event, x, y, flags, param):\n",
    "    global points, pixel_dist\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Store up to 2 points\n",
    "        if len(points) < 2:\n",
    "            points.append((x, y))\n",
    "            print(f\"Point {len(points)} set at: {x, y}\")\n",
    "        \n",
    "        # Once we have 2 points, calculate the Euclidean distance\n",
    "        if len(points) == 2:\n",
    "            x1, y1 = points[0]\n",
    "            x2, y2 = points[1]\n",
    "            pixel_dist = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            print(f\"Distance in Pixels: {pixel_dist:.2f}\")\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\")\n",
    "cv2.namedWindow(\"Calibration\")\n",
    "cv2.setMouseCallback(\"Calibration\", calibrate_dist)\n",
    "\n",
    "print(\"INSTRUCTIONS:\\n1. Click two points to measure a known object.\\n2. Press 'c' to enter real-world size.\\n3. Press 'r' to reset points.\\n4. Press 'Esc' to exit.\")\n",
    "\n",
    "while True:\n",
    "    temp_img = img.copy()\n",
    "    \n",
    "    # Draw the points and the line connecting them\n",
    "    for p in points:\n",
    "        cv2.circle(temp_img, p, 5, (0, 0, 255), -1)\n",
    "    \n",
    "    if len(points) == 2:\n",
    "        cv2.line(temp_img, points[0], points[1], (0, 255, 0), 2)\n",
    "        # Display the calculated real-world distance if scale is set\n",
    "        mid_x = (points[0][0] + points[1][0]) // 2\n",
    "        mid_y = (points[0][1] + points[1][1]) // 2\n",
    "        real_dist = pixel_dist * scale_factor\n",
    "        cv2.putText(temp_img, f\"{real_dist:.2f} units\", (mid_x, mid_y - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Calibration\", temp_img)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == 27: # Esc\n",
    "        break\n",
    "    elif key == ord('r'): # Reset\n",
    "        points = []\n",
    "        print(\"Points reset.\")\n",
    "    elif key == ord('c') and len(points) == 2: # Set Scale\n",
    "        real_val = float(input(\"Enter the actual length of this object (e.g., 30 for 30cm): \"))\n",
    "        scale_factor = real_val / pixel_dist\n",
    "        print(f\"Scale Factor Set: 1 pixel = {scale_factor:.4f} units\")\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165dc53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTRUCTIONS:\n",
      "1. Drag to draw boxes.\n",
      "2. Press 's' to Save to TXT.\n",
      "3. Press 'c' to Clear.\n",
      "4. Press 'Esc' to Quit.\n",
      "Saved 1 labels to labels.txt\n",
      "Saved 2 labels to labels.txt\n"
     ]
    }
   ],
   "source": [
    "# Annotation Tool\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "IMG_PATH = \"dataset/img/uvc.jpg\"\n",
    "LABEL_FILE = \"dataset/labels.txt\"\n",
    "img = cv2.imread(IMG_PATH)\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# State\n",
    "drawing = False\n",
    "ix, iy = -1, -1\n",
    "cx, cy = -1, -1\n",
    "annotations = []\n",
    "\n",
    "def annotate(event, x, y, flags, param):\n",
    "    global ix, iy, cx, cy, drawing, annotations\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "        cx, cy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            cx, cy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        # Calculate YOLO Format: [class_id, x_center, y_center, width, height] (normalized 0-1)\n",
    "        x_min, x_max = min(ix, x), max(ix, x)\n",
    "        y_min, y_max = min(iy, y), max(iy, y)\n",
    "        \n",
    "        box_w = (x_max - x_min) / w\n",
    "        box_h = (y_max - y_min) / h\n",
    "        x_center = (x_min + (x_max - x_min) / 2) / w\n",
    "        y_center = (y_min + (y_max - y_min) / 2) / h\n",
    "        \n",
    "        annotations.append((0, x_center, y_center, box_w, box_h))\n",
    "        # Draw permanently on original image\n",
    "        cv2.rectangle(img, (ix, iy), (x, y), (0, 255, 0), 2)\n",
    "\n",
    "cv2.namedWindow(\"Annotator\")\n",
    "cv2.setMouseCallback(\"Annotator\", annotate)\n",
    "\n",
    "print(\"INSTRUCTIONS:\\n1. Drag to draw boxes.\\n2. Press 's' to Save to TXT.\\n3. Press 'c' to Clear.\\n4. Press 'Esc' to Quit.\")\n",
    "\n",
    "while True:\n",
    "    temp_view = img.copy()\n",
    "    if drawing:\n",
    "        cv2.rectangle(temp_view, (ix, iy), (cx, cy), (255, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Annotator\", temp_view)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == 27: break\n",
    "    elif key == ord('c'):\n",
    "        img = cv2.imread(IMG_PATH)\n",
    "        annotations = []\n",
    "    elif key == ord('s'):\n",
    "        with open(LABEL_FILE, \"w\") as f:\n",
    "            for ann in annotations:\n",
    "                f.write(f\"{ann[0]} {ann[1]:.6f} {ann[2]:.6f} {ann[3]:.6f} {ann[4]:.6f}\\n\")\n",
    "        print(f\"Saved {len(annotations)} labels to {LABEL_FILE}\")\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Trackbars (Real-Time Control)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Global image so the callback can see it\n",
    "img = np.zeros((300, 512, 3), np.uint8)\n",
    "\n",
    "def update_display(x):\n",
    "    # Get values from all trackbars\n",
    "    b = cv2.getTrackbarPos(\"Brightness\", \"Control\")\n",
    "    # Apply transformation\n",
    "    display = cv2.convertScaleAbs(img, alpha=1, beta=b)\n",
    "    cv2.imshow(\"Control\", display)\n",
    "\n",
    "cv2.namedWindow(\"Control\")\n",
    "\n",
    "# Set range to 255 for full brightness control\n",
    "# We pass 'update_display' as the callback instead of 'nothing'\n",
    "cv2.createTrackbar(\"Brightness\", \"Control\", 0, 255, update_display)\n",
    "\n",
    "# Initialize the window once\n",
    "update_display(0)\n",
    "\n",
    "while True:\n",
    "    # Now the loop ONLY waits for the 'Esc' key\n",
    "    if cv2.waitKey(10) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 The \"Golden Range\" Finder (Canny & Threshold)\n",
    "# Engineers use trackbars to find the exact thresholds for edge detection. \n",
    "# If the values are too low, you get noise; too high, and you lose the object.\n",
    "\n",
    "import cv2\n",
    "\n",
    "def update(x):\n",
    "    # This try block prevents the crash during initialization\n",
    "    try:\n",
    "        t1 = cv2.getTrackbarPos(\"Threshold1\", \"Tuner\")\n",
    "        t2 = cv2.getTrackbarPos(\"Threshold2\", \"Tuner\")\n",
    "        edges = cv2.Canny(img, t1, t2)\n",
    "        # LIve edge detection tunning\n",
    "        cv2.imshow(\"Tuner\", edges)\n",
    "        \n",
    "    except cv2.error:   # important: Add a check inside your function to ensure the trackbar exists before reading it.\n",
    "        pass \n",
    "\n",
    "\n",
    "img = cv2.imread(\"dataset/img/uvc.jpg\", 0)\n",
    "cv2.namedWindow(\"Tuner\")\n",
    "\n",
    "# Advanced: Setting initial values to common defaults (100, 200)\n",
    "cv2.createTrackbar(\"Threshold1\", \"Tuner\", 100, 500, update)\n",
    "cv2.createTrackbar(\"Threshold2\", \"Tuner\", 200, 500, update)\n",
    "\n",
    "update(0)\n",
    "\n",
    "while True:\n",
    "    # Now the loop ONLY waits for the 'Esc' key\n",
    "    if cv2.waitKey(10) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 The HSV Color Masker (Essential for Robotics)\n",
    "# Robots \"see\" colors by filtering ranges. Because lighting changes, you need a tool to find the exact Lower and Upper bounds for a specific object (like a tennis ball).\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x): pass\n",
    "\n",
    "cv2.namedWindow(\"HSV_Tracker\")\n",
    "# Create 6 trackbars for Min/Max H, S, V\n",
    "cv2.createTrackbar(\"LH\", \"HSV_Tracker\", 0, 179, nothing)\n",
    "cv2.createTrackbar(\"LS\", \"HSV_Tracker\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LV\", \"HSV_Tracker\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"UH\", \"HSV_Tracker\", 179, 179, nothing)\n",
    "cv2.createTrackbar(\"US\", \"HSV_Tracker\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"UV\", \"HSV_Tracker\", 255, 255, nothing)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Get current positions\n",
    "    l_h = cv2.getTrackbarPos(\"LH\", \"HSV_Tracker\")\n",
    "    l_s = cv2.getTrackbarPos(\"LS\", \"HSV_Tracker\")\n",
    "    l_v = cv2.getTrackbarPos(\"LV\", \"HSV_Tracker\")\n",
    "    u_h = cv2.getTrackbarPos(\"UH\", \"HSV_Tracker\")\n",
    "    u_s = cv2.getTrackbarPos(\"US\", \"HSV_Tracker\")\n",
    "    u_v = cv2.getTrackbarPos(\"UV\", \"HSV_Tracker\")\n",
    "\n",
    "    lower = np.array([l_h, l_s, l_v])\n",
    "    upper = np.array([u_h, u_s, u_v])\n",
    "\n",
    "    # Create a mask: only pixels within this range turn white\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    \n",
    "    # Result shows the actual object being tracked\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Result\", res)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e67f6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Toggle Switch\n",
    "# In OpenCV, there is no native \"checkbox\" or \"toggle\" button. Engineers create a Switch by using a trackbar with a range of 0 to 1.\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Callback function (mandatory for trackbars)\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Initialize camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"Live Feed\")\n",
    "\n",
    "# Create a switch: name, window, min, max, callback\n",
    "# Using '0 : OFF \\n1 : ON' as the name makes the UI clear\n",
    "switch_name = \"0 : OFF \\n1 : ON\"\n",
    "cv2.createTrackbar(switch_name, \"Live Feed\", 0, 1, nothing)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Get the current position of the switch (0 or 1)\n",
    "    s = cv2.getTrackbarPos(switch_name, \"Live Feed\")\n",
    "\n",
    "    # Advanced logic: If switch is ON (1), convert to grayscale\n",
    "    if s == 1:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        # Note: imshow needs BGR or Gray. If we stay in Gray, we keep it as is.\n",
    "    else:\n",
    "        # Keep original BGR color\n",
    "        pass\n",
    "\n",
    "    cv2.imshow(\"Live Feed\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27: # Esc key to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e75e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Video Recording\n",
    "# Saving camera feed to file.\n",
    "\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "out = cv2.VideoWriter('output01.mp4v', fourcc, 20.0, (width, height))\n",
    "    \n",
    "\n",
    "# Use a try...finally block to ensure the file is closed no matter what\n",
    "try:\n",
    "    while True:\n",
    "        # recording logic\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow(\"Recording\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    cap.release()\n",
    "    out.release() # Ensures file is saved even if code crashes\n",
    "    \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf412ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing Video...\n"
     ]
    }
   ],
   "source": [
    "# Multi-threading: By moving out.write() to the background_writer thread, the cv2.imshow remains buttery smooth (60+ FPS) even if the hard drive is busy or slow.\n",
    "# Motion-Sensitive HUD: The recording dot turns Red when motion is detected and Yellow when it's just recording a static scene. This is how high-end security NVRs work.\n",
    "# mp4v + .mp4: We switched to modern containers. This file will play on iPhones, Androids, and web browsers without needing VLC.\n",
    "# The Sentinel Pattern: Passing None into the queue at the end is the professional way to shut down worker threads gracefully without losing the last few frames in the buffer.\n",
    "# Gaussian Blur Pre-processing: Motion detection is performed on a blurred grayscale frame to prevent \"digital noise\" or \"light flickering\" from falsely triggering the recording.\n",
    "\n",
    "\n",
    "import cv2\n",
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "# --- 1. THE VIDEO WRITER THREAD ---\n",
    "# This background worker prevents out.write() from lagging the main UI\n",
    "def background_writer(write_queue, out_object):\n",
    "    while True:\n",
    "        frame = write_queue.get()\n",
    "        if frame is None:  # Sentinel value to stop thread\n",
    "            break\n",
    "        out_object.write(frame)\n",
    "        write_queue.task_done()\n",
    "\n",
    "# --- 2. INITIALIZATION ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# 3. Smart Codec: mp4v (modern, high compression)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('smart_record.mp4', fourcc, 20.0, (width, height))\n",
    "\n",
    "# Setup Threading Queue\n",
    "write_queue = Queue(maxsize=128)\n",
    "writer_thread = threading.Thread(target=background_writer, args=(write_queue, out))\n",
    "writer_thread.start()\n",
    "\n",
    "# --- 3. UI & MOTION SETUP ---\n",
    "cv2.namedWindow(\"Zero-Latency Cam\")\n",
    "cv2.createTrackbar(\"Record\", \"Zero-Latency Cam\", 0, 1, lambda x: None)\n",
    "prev_frame = None\n",
    "prev_time = time.time()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # 4. FPS Calculation\n",
    "        current_time = time.time()\n",
    "        fps = 1 / (current_time - prev_time)\n",
    "        prev_time = current_time\n",
    "\n",
    "        # 5. Motion Detection (Dynamic Trigger)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        \n",
    "        motion_detected = False\n",
    "        if prev_frame is not None:\n",
    "            delta = cv2.absdiff(prev_frame, gray)\n",
    "            thresh = cv2.threshold(delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "            # If more than 0.5% of pixels changed, it's motion\n",
    "            if np.sum(thresh) > (width * height * 0.005):\n",
    "                motion_detected = True\n",
    "        prev_frame = gray\n",
    "\n",
    "        # 6. Timestamps & HUD (The Black Box)\n",
    "        display_frame = frame.copy()\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        cv2.putText(display_frame, f\"{timestamp} | FPS: {int(fps)}\", (10, height - 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        # 7. Multi-threaded Recording Logic\n",
    "        rec_switch = cv2.getTrackbarPos(\"Record\", \"Zero-Latency Cam\")\n",
    "        if rec_switch == 1:\n",
    "            # Add watermark to the actual file\n",
    "            file_frame = frame.copy()\n",
    "            cv2.putText(file_frame, timestamp, (10, height - 20), 0, 0.5, (255, 255, 255), 1)\n",
    "            \n",
    "            # Put frame in queue (Background thread picks it up)\n",
    "            if not write_queue.full():\n",
    "                write_queue.put(file_frame)\n",
    "            \n",
    "            # UI Indicator\n",
    "            color = (0, 0, 255) if motion_detected else (0, 255, 255)\n",
    "            cv2.circle(display_frame, (30, 30), 10, color, -1)\n",
    "            cv2.putText(display_frame, \"RECORDING\", (50, 40), 0, 0.6, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Zero-Latency Cam\", display_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "            break\n",
    "\n",
    "# 5. Atomic Safety (Finally block handles crashes)\n",
    "finally:\n",
    "    print(\"Finalizing Video...\")\n",
    "    write_queue.put(None)    # Tell thread to stop\n",
    "    writer_thread.join()     # Wait for remaining frames to save\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfe7c139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 7319.902268760908\n"
     ]
    }
   ],
   "source": [
    "# 8. FPS and Timing\n",
    "# Sometimes your program runs too fast or too slow.\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# code block\n",
    "\n",
    "end = time.time()\n",
    "print(\"FPS:\", 1/(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3845ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
